#!/usr/bin/env python3
"""
é‡è¤‡ãƒ»ä¸è¦ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ
v2.0 - 2025å¹´8æœˆ24æ—¥æ›´æ–°
"""
import os
import ast
import sys
from collections import defaultdict
from pathlib import Path

def get_project_root():
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
    current = Path(__file__).parent
    while current.parent != current:
        if (current / 'src').exists() and (current / 'config').exists():
            return current
        current = current.parent
    return Path.cwd()

def analyze_method_duplicates():
    """ãƒ¡ã‚½ãƒƒãƒ‰é‡è¤‡æ¤œå‡º"""
    project_root = get_project_root()
    
    # ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    files_to_check = [
        project_root / 'src' / 'classes' / 'ui_ai_test.py',
        project_root / 'src' / 'classes' / 'ui_controller_ai.py',
        project_root / 'src' / 'classes' / 'ui_controller.py',
        project_root / 'src' / 'classes' / 'ui_controller_forms.py'
    ]
    
    method_signatures = defaultdict(list)
    
    for file_path in files_to_check:
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        # ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°æƒ…å ±ã‚’åé›†
                        method_info = {
                            'file': str(file_path),
                            'line': node.lineno,
                            'name': node.name,
                            'args': [arg.arg for arg in node.args.args],
                            'docstring': ast.get_docstring(node) or ""
                        }
                        method_signatures[node.name].append(method_info)
                        
            except Exception as e:
                print(f"âš ï¸ {file_path} ãƒ¡ã‚½ãƒƒãƒ‰è§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    return method_signatures

def analyze_imports():
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆé‡è¤‡åˆ†æ"""
    project_root = get_project_root()
    
    python_files = []
    src_dir = project_root / 'src'
    if src_dir.exists():
        for file_path in src_dir.rglob('*.py'):
            python_files.append(file_path)
    
    import_analysis = defaultdict(list)
    
    for file_path in python_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        import_analysis[alias.name].append(str(file_path))
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ''
                    for alias in node.names:
                        import_name = f"{module}.{alias.name}"
                        import_analysis[import_name].append(str(file_path))
        except Exception as e:
            print(f"âš ï¸ {file_path} ã‚¤ãƒ³ãƒãƒ¼ãƒˆè§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    return import_analysis

def detect_backup_files():
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
    project_root = get_project_root()
    
    backup_patterns = [
        'BACKUP_*.py',
        'temp_*.py', 
        '*_backup.py',
        '*_old.py',
        'test_phase_*.py'  # ä¸€æ™‚çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
    ]
    
    backup_files = []
    for pattern in backup_patterns:
        backup_files.extend(project_root.glob(pattern))
    
    return backup_files

def analyze_file_sizes():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†æ"""
    project_root = get_project_root()
    
    key_files = [
        'src/classes/ui_ai_test.py',
        'src/classes/ui_controller_ai.py', 
        'src/classes/ui_controller.py',
        'src/classes/ui_controller_forms.py'
    ]
    
    file_stats = {}
    for file_rel_path in key_files:
        file_path = project_root / file_rel_path
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                file_stats[file_rel_path] = {
                    'lines': len(lines),
                    'size_kb': file_path.stat().st_size / 1024,
                    'methods': len([line for line in lines if line.strip().startswith('def ')])
                }
    
    return file_stats

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” ARIM RDE Tool - é‡è¤‡ãƒ»ä¸è¦ã‚³ãƒ¼ãƒ‰åˆ†æ")
    print("=" * 60)
    
    # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†æ
    print("\nğŸ“Š ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†æ:")
    file_stats = analyze_file_sizes()
    for file_path, stats in file_stats.items():
        print(f"  ğŸ“ {file_path}")
        print(f"     è¡Œæ•°: {stats['lines']:,} è¡Œ")
        print(f"     ã‚µã‚¤ã‚º: {stats['size_kb']:.1f} KB")
        print(f"     ãƒ¡ã‚½ãƒƒãƒ‰æ•°: {stats['methods']} å€‹")
    
    # 2. ãƒ¡ã‚½ãƒƒãƒ‰é‡è¤‡åˆ†æ  
    print("\nğŸ”„ ãƒ¡ã‚½ãƒƒãƒ‰é‡è¤‡åˆ†æ:")
    methods = analyze_method_duplicates()
    duplicate_methods = {k: v for k, v in methods.items() if len(v) > 1}
    
    if duplicate_methods:
        print(f"  âš ï¸ é‡è¤‡ãƒ¡ã‚½ãƒƒãƒ‰ç™ºè¦‹: {len(duplicate_methods)} å€‹")
        for method_name, occurrences in duplicate_methods.items():
            print(f"\n  ğŸ”¸ {method_name}:")
            for occur in occurrences:
                print(f"     - {occur['file']}:{occur['line']}")
                if occur['args']:
                    print(f"       å¼•æ•°: {occur['args']}")
    else:
        print("  âœ… é‡è¤‡ãƒ¡ã‚½ãƒƒãƒ‰ãªã—")
    
    # 3. ã‚¤ãƒ³ãƒãƒ¼ãƒˆé‡è¤‡åˆ†æ
    print("\nğŸ“¦ ã‚¤ãƒ³ãƒãƒ¼ãƒˆé‡è¤‡åˆ†æ:")
    imports = analyze_imports()
    duplicate_imports = {k: v for k, v in imports.items() if len(v) > 3}  # 3ãƒ•ã‚¡ã‚¤ãƒ«ä»¥ä¸Šã§ä½¿ç”¨
    
    if duplicate_imports:
        print(f"  ğŸ“‹ é«˜é »åº¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {len(duplicate_imports)} å€‹")
        for imp, files in list(duplicate_imports.items())[:5]:  # ä¸Šä½5å€‹ã®ã¿è¡¨ç¤º
            print(f"    {imp}: {len(files)} ãƒ•ã‚¡ã‚¤ãƒ«")
    else:
        print("  âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆæœ€é©åŒ–æ¸ˆã¿")
    
    # 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
    print("\nğŸ—‚ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º:")
    backup_files = detect_backup_files()
    
    if backup_files:
        print(f"  ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«: {len(backup_files)} å€‹")
        for backup_file in backup_files:
            print(f"    - {backup_file.name}")
    else:
        print("  âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    
    # 5. ç·åˆè©•ä¾¡
    print("\nğŸ¯ ç·åˆè©•ä¾¡:")
    total_duplicates = len(duplicate_methods)
    total_backups = len(backup_files)
    
    if total_duplicates == 0 and total_backups == 0:
        print("  âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†çŠ¶æ…‹")
    else:
        print(f"  âš ï¸ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¿…è¦: é‡è¤‡{total_duplicates}å€‹, ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—{total_backups}å€‹")
        
        # å„ªå…ˆé †ä½ä»˜ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ
        print("\nğŸ“‹ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        if total_duplicates > 0:
            print("  1. ãƒ¡ã‚½ãƒƒãƒ‰é‡è¤‡è§£æ¶ˆ (é«˜å„ªå…ˆåº¦)")
        if total_backups > 0:
            print("  2. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç† (ä¸­å„ªå…ˆåº¦)")
    
    print("\n" + "=" * 60)
    print("åˆ†æå®Œäº†")

if __name__ == "__main__":
    main()
