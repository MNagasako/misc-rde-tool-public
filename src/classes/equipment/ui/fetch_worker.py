"""
è¨­å‚™ã‚¿ãƒ– - ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ¯ãƒ¼ã‚«ãƒ¼

è¨­å‚™ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã™ã€‚
"""

import logging
from datetime import datetime
from typing import Optional

from classes.equipment.util.output_paths import get_equipment_root_dir
from classes.equipment.core.fetch_range_builder import collect_valid_facility_ids
from classes.equipment.core.facility_listing import FacilityListingScraper

logger = logging.getLogger(__name__)

try:
    from qt_compat.core import QThread, Signal
    PYSIDE6_AVAILABLE = True
except ImportError as e:
    PYSIDE6_AVAILABLE = False
    logger.error(f"Qtäº’æ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    raise ImportError(f"Qtäº’æ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå¿…è¦ã§ã™: {e}")


class FacilityFetchWorker(QThread):
    """è¨­å‚™ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰
    
    ParallelFacilityFetcherã‚’ä½¿ç”¨ã—ã¦è¨­å‚™ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦åˆ—å–å¾—ã—ã¾ã™ã€‚
    """
    
    # ã‚·ã‚°ãƒŠãƒ«å®šç¾©
    progress = Signal(int, int, str)  # current, total, message
    completed = Signal(int, int)  # success_count, error_count
    log_message = Signal(str)
    results = Signal(dict)  # file_results
    
    def __init__(
        self,
        start_id: int,
        end_id: int,
        max_workers: int = 5,
        export_excel: bool = True,
        export_json: bool = True,
        export_entries: bool = True,
        consecutive_not_found_limit: Optional[int] = None,
        fetch_all_chunk_size: Optional[int] = None,
        parent=None
    ):
        super().__init__(parent)
        
        self.start_id = start_id
        self.end_id = end_id
        self.max_workers = max_workers
        self.export_excel = export_excel
        self.export_json = export_json
        self.export_entries = export_entries
        self.consecutive_not_found_limit = consecutive_not_found_limit
        self.fetch_all_chunk_size = fetch_all_chunk_size
        
        self.cancel_requested = False
    
    def run(self):
        """å–å¾—å‡¦ç†å®Ÿè¡Œ"""
        try:
            from classes.equipment.core.parallel_fetcher import ParallelFacilityFetcher
            from classes.equipment.core.data_processor import FacilityDataProcessor
            from classes.equipment.core.file_exporter import FacilityExporter
            
            equipment_dir = get_equipment_root_dir()
            self.log_message.emit(f"ğŸ“‚ è¨­å‚™å‡ºåŠ›å…ˆ: {equipment_dir}")
            
            # é€£ç¶šä¸åœ¨åˆ¤å®šãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹
            if self.consecutive_not_found_limit:
                chunk_size = self.fetch_all_chunk_size or 1
                facility_ids = collect_valid_facility_ids(
                    start_id=self.start_id,
                    end_id=self.end_id,
                    chunk_size=chunk_size,
                    stop_threshold=self.consecutive_not_found_limit,
                    log_callback=self.log_message.emit,
                    cancel_checker=lambda: self.cancel_requested,
                    listing_scraper=FacilityListingScraper()
                )
            else:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: æŒ‡å®šç¯„å›²ã™ã¹ã¦
                facility_ids = list(range(self.start_id, self.end_id + 1))
            
            if not facility_ids:
                self.log_message.emit("âš  å–å¾—ã™ã‚‹è¨­å‚™IDãŒã‚ã‚Šã¾ã›ã‚“")
                self.completed.emit(0, 0)
                return
            
            total_count = len(facility_ids)
            self.log_message.emit(f"ğŸ”„ {total_count}ä»¶ã®è¨­å‚™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—é–‹å§‹...")
            
            # ä¸¦åˆ—å–å¾—
            fetcher = ParallelFacilityFetcher(max_workers=self.max_workers)
            
            def progress_callback(current, total, message):
                """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
                self.progress.emit(current, total, message)
                self.log_message.emit(f"[{current}/{total}] {message}")
                return not self.cancel_requested
            
            success_data, error_info = fetcher.fetch_facilities_with_results(
                facility_ids=facility_ids,
                progress_callback=progress_callback
            )
            
            success_count = len(success_data)
            error_count = len(error_info)
            
            self.log_message.emit(f"âœ… å–å¾—å®Œäº†: æˆåŠŸ={success_count}, å¤±æ•—={error_count}")
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            if success_data:
                self.log_message.emit("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
                processor = FacilityDataProcessor()
                processed_data, process_errors = processor.process_batch(success_data)
                
                self.log_message.emit(f"âœ… {len(processed_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†")
                if process_errors:
                    self.log_message.emit(f"âš  {len(process_errors)}ä»¶ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
                exporter = FacilityExporter()
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                base_filename = f"facilities_{timestamp}"
                
                if self.export_excel and self.export_json:
                    # Excel+JSONå‡ºåŠ›ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãï¼‰
                    self.log_message.emit("ğŸ“ŠğŸ“„ Excel/JSONå‡ºåŠ›ä¸­ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãï¼‰...")
                    file_results = exporter.export_with_backup(processed_data, base_filename)
                    latest_excel = file_results.get('latest_excel')
                    latest_json = file_results.get('latest_json')
                    backup_dir = file_results.get('backup_dir')
                    self.log_message.emit(f"âœ… Excelå‡ºåŠ›å®Œäº†: {latest_excel}")
                    self.log_message.emit(f"âœ… JSONå‡ºåŠ›å®Œäº†: {latest_json}")
                    self.log_message.emit(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_dir}")
                else:
                    # å€‹åˆ¥å‡ºåŠ›
                    latest_excel = None
                    latest_json = None
                    backup_dir = None
                    
                    if self.export_excel:
                        self.log_message.emit("ğŸ“Š Excelå‡ºåŠ›ä¸­...")
                        latest_excel = exporter.export_excel(processed_data, f"{base_filename}.xlsx")
                        self.log_message.emit(f"âœ… Excelå‡ºåŠ›å®Œäº†: {latest_excel}")
                    
                    if self.export_json:
                        self.log_message.emit("ğŸ“„ JSONå‡ºåŠ›ä¸­...")
                        latest_json = exporter.export_json(processed_data, f"{base_filename}.json")
                        self.log_message.emit(f"âœ… JSONå‡ºåŠ›å®Œäº†: {latest_json}")
                
                if self.export_entries:
                    self.log_message.emit("ğŸ“ å€‹åˆ¥ã‚¨ãƒ³ãƒˆãƒªå‡ºåŠ›ä¸­...")
                    entry_dir = exporter.export_json_entries(processed_data)
                    self.log_message.emit(f"âœ… å€‹åˆ¥ã‚¨ãƒ³ãƒˆãƒªå‡ºåŠ›å®Œäº†: {entry_dir}")
                
                # çµæœé€ä¿¡
                self.results.emit({
                    'latest_excel': latest_excel,
                    'latest_json': latest_json,
                    'backup_dir': backup_dir
                })
            else:
                self.log_message.emit("âš  å–å¾—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            
            # å®Œäº†é€šçŸ¥
            self.completed.emit(success_count, error_count)
        
        except Exception as e:
            logger.exception("è¨­å‚™ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼")
            self.log_message.emit(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.completed.emit(0, 0)
    
    def cancel(self):
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«è¦æ±‚"""
        self.cancel_requested = True
