"""
è¨­å‚™ã‚¿ãƒ– - ä¸€æ‹¬å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼

ãƒ‡ãƒ¼ã‚¿å–å¾—â†’ã‚«ã‚¿ãƒ­ã‚°å¤‰æ›â†’ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ã‚’ä¸€æ‹¬ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã™ã€‚
"""

import logging
from typing import Optional
from datetime import datetime
from classes.equipment.core.fetch_range_builder import collect_valid_facility_ids
from classes.equipment.core.facility_listing import FacilityListingScraper

logger = logging.getLogger(__name__)

try:
    from qt_compat.core import QThread, Signal
    PYSIDE6_AVAILABLE = True
except ImportError as e:
    PYSIDE6_AVAILABLE = False
    logger.error(f"Qtäº’æ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    raise ImportError(f"Qtäº’æ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå¿…è¦ã§ã™: {e}")


class BatchProcessWorker(QThread):
    """ä¸€æ‹¬å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰
    
    è¨­å‚™ãƒ‡ãƒ¼ã‚¿å–å¾—â†’ã‚«ã‚¿ãƒ­ã‚°å¤‰æ›â†’ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ã‚’è‡ªå‹•ã§å®Ÿè¡Œã—ã¾ã™ã€‚
    """
    
    # ã‚·ã‚°ãƒŠãƒ«å®šç¾©
    progress = Signal(int, int, str)  # current, total, message
    completed = Signal(bool, str)  # success, message
    log_message = Signal(str)
    results = Signal(dict)  # file_results
    
    def __init__(
        self,
        start_id: int,
        end_id: int,
        max_workers: int = 5,
        fetch_all: bool = False,
        consecutive_not_found_limit: Optional[int] = None,
        fetch_all_chunk_size: Optional[int] = None,
        parent=None
    ):
        super().__init__(parent)
        
        self.start_id = start_id
        self.end_id = end_id
        self.max_workers = max_workers
        self.fetch_all = fetch_all
        self.consecutive_not_found_limit = consecutive_not_found_limit
        self.fetch_all_chunk_size = fetch_all_chunk_size
        
        self.cancel_requested = False
    
    def run(self):
        """ä¸€æ‹¬å‡¦ç†å®Ÿè¡Œ"""
        try:
            # ========================================
            # Step 1: è¨­å‚™ãƒ‡ãƒ¼ã‚¿å–å¾—
            # ========================================
            self.log_message.emit("=" * 60)
            self.log_message.emit("ğŸ“Š Step 1/3: è¨­å‚™ãƒ‡ãƒ¼ã‚¿å–å¾—")
            self.log_message.emit("=" * 60)
            
            from classes.equipment.core.parallel_fetcher import ParallelFacilityFetcher
            from classes.equipment.core.data_processor import FacilityDataProcessor
            from classes.equipment.core.file_exporter import FacilityExporter
            
            # å–å¾—ç¯„å›²ç”Ÿæˆ
            if (
                self.fetch_all
                and self.consecutive_not_found_limit
                and self.fetch_all_chunk_size
            ):
                facility_ids = collect_valid_facility_ids(
                    start_id=self.start_id,
                    end_id=self.end_id,
                    chunk_size=self.fetch_all_chunk_size,
                    stop_threshold=self.consecutive_not_found_limit,
                    log_callback=self.log_message.emit,
                    cancel_checker=lambda: self.cancel_requested,
                    listing_scraper=FacilityListingScraper()
                )
            else:
                facility_ids = list(range(self.start_id, self.end_id + 1))

            if not facility_ids:
                self.log_message.emit("âš  å–å¾—ã™ã‚‹è¨­å‚™IDãŒã‚ã‚Šã¾ã›ã‚“")
                self.completed.emit(False, "å–å¾—å¯¾è±¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return

            total_count = len(facility_ids)
            self.log_message.emit(f"ğŸ”„ {total_count}ä»¶ã®è¨­å‚™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—é–‹å§‹...")
            
            # ä¸¦åˆ—å–å¾—
            fetcher = ParallelFacilityFetcher(max_workers=self.max_workers)
            
            def fetch_progress_callback(current, total, message):
                """å–å¾—ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
                self.progress.emit(current, total, f"[å–å¾—] {message}")
                self.log_message.emit(f"[å–å¾— {current}/{total}] {message}")
                return not self.cancel_requested
            
            success_data, error_info = fetcher.fetch_facilities_with_results(
                facility_ids=facility_ids,
                progress_callback=fetch_progress_callback
            )
            
            success_count = len(success_data)
            error_count = len(error_info)
            
            self.log_message.emit(f"âœ… å–å¾—å®Œäº†: æˆåŠŸ={success_count}, å¤±æ•—={error_count}")
            
            if not success_data:
                self.completed.emit(False, "è¨­å‚™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            self.log_message.emit("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
            processor = FacilityDataProcessor()
            processed_data, process_errors = processor.process_batch(success_data)
            
            self.log_message.emit(f"âœ… {len(processed_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            exporter = FacilityExporter()
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_filename = f"facilities_{timestamp}"
            
            self.log_message.emit("ğŸ“ŠğŸ“„ Excel/JSONå‡ºåŠ›ä¸­ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãï¼‰...")
            file_results = exporter.export_with_backup(processed_data, base_filename)
            latest_excel = file_results.get('latest_excel')
            latest_json = file_results.get('latest_json')
            backup_dir = file_results.get('backup_dir')
            
            self.log_message.emit(f"âœ… Excelå‡ºåŠ›å®Œäº†: {latest_excel}")
            self.log_message.emit(f"âœ… JSONå‡ºåŠ›å®Œäº†: {latest_json}")
            
            # facilities_full.xlsx ã¨ã—ã¦ã‚‚ã‚³ãƒ”ãƒ¼ï¼ˆãƒãƒ¼ã‚¸ç”¨ï¼‰
            import shutil
            import os
            facilities_full_path = os.path.join(os.path.dirname(latest_excel), "facilities_full.xlsx")
            shutil.copy2(latest_excel, facilities_full_path)
            self.log_message.emit(f"ğŸ“‹ facilities_full.xlsx ã‚’ä½œæˆ: {facilities_full_path}")
            
            # ========================================
            # Step 2: ã‚«ã‚¿ãƒ­ã‚°å¤‰æ›
            # ========================================
            self.log_message.emit("=" * 60)
            self.log_message.emit("ğŸ”„ Step 2/3: ã‚«ã‚¿ãƒ­ã‚°å¤‰æ›ï¼ˆExcelâ†’JSONï¼‰")
            self.log_message.emit("=" * 60)
            
            from classes.equipment.core.catalog_converter import CatalogConverter
            
            converter = CatalogConverter()
            
            def convert_progress_callback(current, total, message):
                """å¤‰æ›ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
                self.log_message.emit(f"[å¤‰æ› {current}/{total}] {message}")
            
            result_convert = converter.convert_catalog_to_json(
                prefix="ARIM è¨ˆæ¸¬è£…ç½®ã‚«ã‚¿ãƒ­ã‚°",
                output_filename="fasi_ext.json",
                progress_callback=convert_progress_callback
            )
            
            if not result_convert.get('success'):
                self.log_message.emit(f"âš  ã‚«ã‚¿ãƒ­ã‚°å¤‰æ›ã‚¹ã‚­ãƒƒãƒ—: {result_convert.get('error')}")
            else:
                self.log_message.emit(f"âœ… ã‚«ã‚¿ãƒ­ã‚°å¤‰æ›å®Œäº†: {result_convert['output_path']}")
            
            # ========================================
            # Step 3: ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸
            # ========================================
            self.log_message.emit("=" * 60)
            self.log_message.emit("ğŸ”— Step 3/3: ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ï¼ˆExcel+JSONï¼‰")
            self.log_message.emit("=" * 60)
            
            from classes.equipment.core.data_merger import DataMerger
            
            merger = DataMerger()
            
            def merge_progress_callback(current, total, message):
                """ãƒãƒ¼ã‚¸ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
                self.log_message.emit(f"[ãƒãƒ¼ã‚¸ {current}/{total}] {message}")
            
            result_merge = merger.merge_excel_json(
                excel_filename="facilities_full.xlsx",
                json_filename="fasi_ext.json",
                output_filename="merged_data2.json",
                progress_callback=merge_progress_callback
            )
            
            if not result_merge.get('success'):
                self.log_message.emit(f"âš  ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ã‚¹ã‚­ãƒƒãƒ—: {result_merge.get('error')}")
            else:
                self.log_message.emit(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸å®Œäº†: {result_merge['output_path']}")
                self.log_message.emit(f"ğŸ“Š çµ±åˆä»¶æ•°: {result_merge['merged_count']}, methods: {result_merge['methods_matched']}")
            
            # ========================================
            # å®Œäº†
            # ========================================
            
            # çµæœé€ä¿¡
            self.results.emit({
                'latest_excel': latest_excel,
                'latest_json': latest_json,
                'backup_dir': backup_dir
            })
            
            # å®Œäº†é€šçŸ¥
            summary = (
                f"è¨­å‚™ãƒ‡ãƒ¼ã‚¿å–å¾—: æˆåŠŸ={success_count}, å¤±æ•—={error_count}\n"
                f"ã‚«ã‚¿ãƒ­ã‚°å¤‰æ›: {'âœ… å®Œäº†' if result_convert.get('success') else 'âš  ã‚¹ã‚­ãƒƒãƒ—'}\n"
                f"ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸: {'âœ… å®Œäº†' if result_merge.get('success') else 'âš  ã‚¹ã‚­ãƒƒãƒ—'}"
            )
            self.completed.emit(True, summary)
        
        except Exception as e:
            logger.exception("ä¸€æ‹¬å‡¦ç†ã‚¨ãƒ©ãƒ¼")
            self.log_message.emit(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.completed.emit(False, str(e))
    
    def cancel(self):
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«è¦æ±‚"""
        self.cancel_requested = True
